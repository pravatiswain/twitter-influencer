{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capstone 2: Twitter Data Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visit the Application Management page at https://apps.twitter.com/, and sign in with your Twitter account\n",
    "\n",
    "- Click on the \"Create New App\" button, fill in the details and agree the Terms of Service\n",
    "- Navigate to \"Keys and Access Tokens\" section and take a note of your Consumer Key and Secret\n",
    "- In the same section click on \"Create my access token\" button\n",
    "- Take note of your Access Token and Access Token Secret\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import tweepy\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input credentials (keys and Access tokens)\n",
    "\n",
    "consumer_key = 'hoxaNCoEPTzag21rnrM9DgVLO'\n",
    "consumer_secret = 'mOrO9LdpJsHpYxFPKS09acqxU3cfFCyBKg3IxE5FuQo4Wm1Blg'\n",
    "access_token = '788192317350023168-FNFlFSR0jJSD0AHSTMkEpiscYDhp5Ug'\n",
    "access_token_secret = 'fr3JKLbnJtWmXiDzhppfBSExUtFghQA3w7DISG03Xw5Ar'\n",
    "\n",
    "##pass the credentials into Tweepyâ€™s OAuthHandler instance \n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to scrape the tweets for different hashtags\n",
    "\n",
    "def scrape_tweets(search_words, num_tweets, num_runs, csv_file_name):\n",
    "    \n",
    "    program_start = time.time()\n",
    "    \n",
    "    # Open/Create a file to append data\n",
    "    csvFile = open(csv_file_name, 'a')\n",
    "    #Use csv Writer\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "    csvWriter.writerow(['user_name', 'user_desc', 'location', 'following',\n",
    "                                        'followers', 'totaltweets', 'user_createdts', 'tweet_createdts',\n",
    "                                        'retweet_count', 'text'])\n",
    "    for i in range(0, num_runs):\n",
    "        new_tweets = tweepy.Cursor(api.search, q=search_words, lang=\"en\", tweet_mode='extended').items(num_tweets)\n",
    "        \n",
    "        # transform the tweepy tweets into a 2D array \n",
    "        outtweets = [[tweet.user.screen_name,tweet.user.description,tweet.user.location,tweet.user.friends_count,\n",
    "                  tweet.user.followers_count,tweet.user.statuses_count,tweet.user.created_at,\n",
    "                  tweet.created_at,tweet.retweet_count, tweet.full_text] for tweet in new_tweets]\n",
    "        \n",
    "        csvWriter.writerows(outtweets)\n",
    "        print(\"{} run completed!\".format(i+1))\n",
    "        time.sleep(920) #15 minute sleep time\n",
    "    \n",
    "    program_end = time.time()\n",
    "    print('Scraping has completed!')\n",
    "    print('Total time taken to scrape is {} minutes.'.format(round(program_end - program_start)/60, 2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_tweets_2(search_words, num_tweets, num_runs, csv_file_name):\n",
    "    \n",
    "    program_start = time.time()\n",
    "    \n",
    "    # Open/Create a file to append data\n",
    "    csvFile = open(csv_file_name, 'a')\n",
    "    #Use csv Writer\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "    #csvWriter.writerow(['user_name', 'user_desc', 'location', 'following',\n",
    "                                        #'followers', 'totaltweets', 'user_createdts', 'tweet_createdts',\n",
    "                                        #'retweet_count', 'text'])\n",
    "    for i in range(0, num_runs):\n",
    "        new_tweets = tweepy.Cursor(api.search, q=search_words, lang=\"en\", tweet_mode='extended').items(num_tweets)\n",
    "        \n",
    "        # transform the tweepy tweets into a 2D array \n",
    "        outtweets = [[tweet.user.screen_name,tweet.user.description,tweet.user.location,tweet.user.friends_count,\n",
    "                  tweet.user.followers_count,tweet.user.statuses_count,tweet.user.created_at,\n",
    "                  tweet.created_at,tweet.retweet_count, tweet.full_text] for tweet in new_tweets]\n",
    "        \n",
    "        csvWriter.writerows(outtweets)\n",
    "        print(\"{} run completed!\".format(i+1))\n",
    "        time.sleep(920) #15 minute sleep time\n",
    "    \n",
    "    program_end = time.time()\n",
    "    print('Scraping has completed!')\n",
    "    print('Total time taken to scrape is {} minutes.'.format(round(program_end - program_start)/60, 2))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulling tweets for #fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tags = ['#fashion', '#style',  '#design',  '#beauty',  '#fashiontrends',  '#fashionblogger', '#fashionstyle',  '#fashionweek',  '#fashionstylist',  '#fashionmodel' , '#fasionista' , '#model',  '#fashionlover',  '#womenfashion', '#menfashion']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 run completed!\n",
      "2 run completed!\n",
      "3 run completed!\n",
      "4 run completed!\n",
      "5 run completed!\n",
      "6 run completed!\n",
      "7 run completed!\n",
      "8 run completed!\n",
      "9 run completed!\n",
      "10 run completed!\n",
      "11 run completed!\n",
      "12 run completed!\n",
      "13 run completed!\n",
      "14 run completed!\n",
      "15 run completed!\n",
      "16 run completed!\n",
      "17 run completed!\n",
      "18 run completed!\n",
      "19 run completed!\n",
      "20 run completed!\n",
      "21 run completed!\n",
      "22 run completed!\n",
      "23 run completed!\n",
      "24 run completed!\n",
      "25 run completed!\n",
      "26 run completed!\n",
      "27 run completed!\n",
      "28 run completed!\n",
      "29 run completed!\n",
      "30 run completed!\n",
      "31 run completed!\n",
      "32 run completed!\n",
      "33 run completed!\n",
      "34 run completed!\n",
      "35 run completed!\n",
      "36 run completed!\n",
      "37 run completed!\n",
      "38 run completed!\n",
      "39 run completed!\n",
      "40 run completed!\n",
      "41 run completed!\n",
      "42 run completed!\n",
      "43 run completed!\n",
      "44 run completed!\n",
      "45 run completed!\n",
      "46 run completed!\n",
      "47 run completed!\n",
      "48 run completed!\n",
      "49 run completed!\n",
      "50 run completed!\n",
      "Scraping has completed!\n",
      "Total time taken to scrape is 771.0833333333334 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Initialise these variables for #fashion\n",
    "search_words = \"#fashion OR #style OR #design OR #beauty OR #fashiontrends OR #fashionblogger OR #fashionstyle OR #fashionweek OR #fashionstylist OR #fashionmodel OR #fasionista OR #model OR #fashionlover OR #womenfashion OR #menfashion\"\n",
    "num_tweets = 200\n",
    "num_runs = 50\n",
    "csv_file_name = 'fashion_tweets_allf.csv'\n",
    "\n",
    "\n",
    "# Call the function scrape_tweets\n",
    "scrape_tweets(search_words, num_tweets, num_runs, csv_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling tweets for #fashion (2nd, 3rd..10th time)  using the `scrape_tweets_2 ()` function\n",
    "\n",
    "Every day I am pulling 10,000 tweets for 10 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 run completed!\n",
      "2 run completed!\n",
      "3 run completed!\n",
      "4 run completed!\n",
      "5 run completed!\n",
      "6 run completed!\n",
      "7 run completed!\n",
      "8 run completed!\n",
      "9 run completed!\n",
      "10 run completed!\n",
      "11 run completed!\n",
      "12 run completed!\n",
      "13 run completed!\n",
      "14 run completed!\n",
      "15 run completed!\n",
      "16 run completed!\n",
      "17 run completed!\n",
      "18 run completed!\n",
      "19 run completed!\n",
      "20 run completed!\n",
      "21 run completed!\n",
      "22 run completed!\n",
      "23 run completed!\n",
      "24 run completed!\n",
      "25 run completed!\n",
      "26 run completed!\n",
      "27 run completed!\n",
      "28 run completed!\n",
      "29 run completed!\n",
      "30 run completed!\n",
      "31 run completed!\n",
      "32 run completed!\n",
      "33 run completed!\n",
      "34 run completed!\n",
      "35 run completed!\n",
      "36 run completed!\n",
      "37 run completed!\n",
      "38 run completed!\n",
      "39 run completed!\n",
      "40 run completed!\n",
      "41 run completed!\n",
      "42 run completed!\n",
      "43 run completed!\n",
      "44 run completed!\n",
      "45 run completed!\n",
      "46 run completed!\n",
      "47 run completed!\n",
      "48 run completed!\n",
      "49 run completed!\n",
      "50 run completed!\n",
      "Scraping has completed!\n",
      "Total time taken to scrape is 771.2833333333333 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Initialise these variables for #fashion\n",
    "search_words = \"#fashion OR #style OR #design OR #beauty OR #fashiontrends OR #fashionblogger OR #fashionstyle OR #fashionweek OR #fashionstylist OR #fashionmodel OR #fasionista OR #model OR #fashionlover OR #womenfashion OR #menfashion\"\n",
    "num_tweets = 200\n",
    "num_runs = 50\n",
    "csv_file_name = 'fashion_tweets_allf.csv'\n",
    "\n",
    "\n",
    "# Call the function scrape_tweets\n",
    "scrape_tweets_2(search_words, num_tweets, num_runs, csv_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_desc</th>\n",
       "      <th>location</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>totaltweets</th>\n",
       "      <th>user_createdts</th>\n",
       "      <th>tweet_createdts</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michelleferg79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4981</td>\n",
       "      <td>669</td>\n",
       "      <td>98487</td>\n",
       "      <td>2013-10-25 18:38:52</td>\n",
       "      <td>2020-10-04 17:40:05</td>\n",
       "      <td>174</td>\n",
       "      <td>RT @AnythingGoesL: #Win the 3-Step Anthology f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GillybeansH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>England</td>\n",
       "      <td>4637</td>\n",
       "      <td>238</td>\n",
       "      <td>15409</td>\n",
       "      <td>2009-05-10 13:18:12</td>\n",
       "      <td>2020-10-04 17:40:05</td>\n",
       "      <td>476</td>\n",
       "      <td>RT @So_Lippy: Enter our #October #Competition ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>luccaromeo</td>\n",
       "      <td>Everything has beauty, but not everyone sees i...</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>275</td>\n",
       "      <td>179</td>\n",
       "      <td>21939</td>\n",
       "      <td>2015-09-08 17:43:34</td>\n",
       "      <td>2020-10-04 17:40:03</td>\n",
       "      <td>0</td>\n",
       "      <td>Visage de Layla also offers waxing treatment h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FashListings</td>\n",
       "      <td>Sell fashion? List your business for FREE in o...</td>\n",
       "      <td>Northampton, UK</td>\n",
       "      <td>30747</td>\n",
       "      <td>35104</td>\n",
       "      <td>224859</td>\n",
       "      <td>2014-12-27 15:53:24</td>\n",
       "      <td>2020-10-04 17:40:03</td>\n",
       "      <td>0</td>\n",
       "      <td>Sell #fashion? Submit your website to our #dir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_Fanii10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>32</td>\n",
       "      <td>2015-06-21 21:26:09</td>\n",
       "      <td>2020-10-04 17:39:57</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @theregoesjared: Candy Battle ğŸ¬ğŸ­ğŸ«\\nStarburs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_name                                          user_desc  \\\n",
       "0  Michelleferg79                                                NaN   \n",
       "1     GillybeansH                                                NaN   \n",
       "2      luccaromeo  Everything has beauty, but not everyone sees i...   \n",
       "3    FashListings  Sell fashion? List your business for FREE in o...   \n",
       "4        _Fanii10                                                NaN   \n",
       "\n",
       "          location  following  followers  totaltweets       user_createdts  \\\n",
       "0              NaN       4981        669        98487  2013-10-25 18:38:52   \n",
       "1          England       4637        238        15409  2009-05-10 13:18:12   \n",
       "2  Los Angeles, CA        275        179        21939  2015-09-08 17:43:34   \n",
       "3  Northampton, UK      30747      35104       224859  2014-12-27 15:53:24   \n",
       "4              NaN         25         36           32  2015-06-21 21:26:09   \n",
       "\n",
       "       tweet_createdts  retweet_count  \\\n",
       "0  2020-10-04 17:40:05            174   \n",
       "1  2020-10-04 17:40:05            476   \n",
       "2  2020-10-04 17:40:03              0   \n",
       "3  2020-10-04 17:40:03              0   \n",
       "4  2020-10-04 17:39:57              1   \n",
       "\n",
       "                                                text  \n",
       "0  RT @AnythingGoesL: #Win the 3-Step Anthology f...  \n",
       "1  RT @So_Lippy: Enter our #October #Competition ...  \n",
       "2  Visage de Layla also offers waxing treatment h...  \n",
       "3  Sell #fashion? Submit your website to our #dir...  \n",
       "4  RT @theregoesjared: Candy Battle ğŸ¬ğŸ­ğŸ«\\nStarburs...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data into a pandas DataFrame\n",
    "fashion_df = pd.read_csv('fashion_tweets_allf.csv')\n",
    "fashion_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out total no of rows and columns\n",
    "fashion_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any missing value?\n",
    "fashion_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   user_name        50000 non-null  object\n",
      " 1   user_desc        43714 non-null  object\n",
      " 2   location         33476 non-null  object\n",
      " 3   following        50000 non-null  int64 \n",
      " 4   followers        50000 non-null  int64 \n",
      " 5   totaltweets      50000 non-null  int64 \n",
      " 6   user_createdts   50000 non-null  object\n",
      " 7   tweet_createdts  50000 non-null  object\n",
      " 8   retweet_count    50000 non-null  int64 \n",
      " 9   text             50000 non-null  object\n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Count missing values\n",
    "fashion_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22810\n"
     ]
    }
   ],
   "source": [
    "# Total number of missing values\n",
    "print(fashion_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16416"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicate tweets \n",
    "\n",
    "duplicate_tweets_fashion = fashion_df.duplicated(subset='text', keep='first').sum()\n",
    "duplicate_tweets_fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15553"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of users having less than 2000 followers\n",
    "fashion_less2k = fashion_df[fashion_df['followers'] < 2000]\n",
    "len(fashion_less2k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of users having more than 2000 followers\n",
    "fashion_more2k = fashion_df[fashion_df['followers'] > 30000]\n",
    "len(fashion_more2k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_desc</th>\n",
       "      <th>location</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>totaltweets</th>\n",
       "      <th>user_createdts</th>\n",
       "      <th>tweet_createdts</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michelleferg79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4981</td>\n",
       "      <td>669</td>\n",
       "      <td>98487</td>\n",
       "      <td>2013-10-25 18:38:52</td>\n",
       "      <td>2020-10-04 17:40:05</td>\n",
       "      <td>174</td>\n",
       "      <td>RT @AnythingGoesL: #Win the 3-Step Anthology f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GillybeansH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>England</td>\n",
       "      <td>4637</td>\n",
       "      <td>238</td>\n",
       "      <td>15409</td>\n",
       "      <td>2009-05-10 13:18:12</td>\n",
       "      <td>2020-10-04 17:40:05</td>\n",
       "      <td>476</td>\n",
       "      <td>RT @So_Lippy: Enter our #October #Competition ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>luccaromeo</td>\n",
       "      <td>Everything has beauty, but not everyone sees i...</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>275</td>\n",
       "      <td>179</td>\n",
       "      <td>21939</td>\n",
       "      <td>2015-09-08 17:43:34</td>\n",
       "      <td>2020-10-04 17:40:03</td>\n",
       "      <td>0</td>\n",
       "      <td>Visage de Layla also offers waxing treatment h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FashListings</td>\n",
       "      <td>Sell fashion? List your business for FREE in o...</td>\n",
       "      <td>Northampton, UK</td>\n",
       "      <td>30747</td>\n",
       "      <td>35104</td>\n",
       "      <td>224859</td>\n",
       "      <td>2014-12-27 15:53:24</td>\n",
       "      <td>2020-10-04 17:40:03</td>\n",
       "      <td>0</td>\n",
       "      <td>Sell #fashion? Submit your website to our #dir...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_Fanii10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>32</td>\n",
       "      <td>2015-06-21 21:26:09</td>\n",
       "      <td>2020-10-04 17:39:57</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @theregoesjared: Candy Battle ğŸ¬ğŸ­ğŸ«\\nStarburs...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_name                                          user_desc  \\\n",
       "0  Michelleferg79                                                NaN   \n",
       "1     GillybeansH                                                NaN   \n",
       "2      luccaromeo  Everything has beauty, but not everyone sees i...   \n",
       "3    FashListings  Sell fashion? List your business for FREE in o...   \n",
       "4        _Fanii10                                                NaN   \n",
       "\n",
       "          location  following  followers  totaltweets       user_createdts  \\\n",
       "0              NaN       4981        669        98487  2013-10-25 18:38:52   \n",
       "1          England       4637        238        15409  2009-05-10 13:18:12   \n",
       "2  Los Angeles, CA        275        179        21939  2015-09-08 17:43:34   \n",
       "3  Northampton, UK      30747      35104       224859  2014-12-27 15:53:24   \n",
       "4              NaN         25         36           32  2015-06-21 21:26:09   \n",
       "\n",
       "       tweet_createdts  retweet_count  \\\n",
       "0  2020-10-04 17:40:05            174   \n",
       "1  2020-10-04 17:40:05            476   \n",
       "2  2020-10-04 17:40:03              0   \n",
       "3  2020-10-04 17:40:03              0   \n",
       "4  2020-10-04 17:39:57              1   \n",
       "\n",
       "                                                text  label  \n",
       "0  RT @AnythingGoesL: #Win the 3-Step Anthology f...      0  \n",
       "1  RT @So_Lippy: Enter our #October #Competition ...      0  \n",
       "2  Visage de Layla also offers waxing treatment h...      0  \n",
       "3  Sell #fashion? Submit your website to our #dir...      1  \n",
       "4  RT @theregoesjared: Candy Battle ğŸ¬ğŸ­ğŸ«\\nStarburs...      0  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_func(followers):\n",
    "    if followers > 30000:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "fashion_df['label'] = fashion_df['followers'].apply(label_func)\n",
    "fashion_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling tweets for #fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to scrape the tweets for different hashtags\n",
    "\n",
    "def scrape_tweets(search_words, num_tweets, num_runs, csv_file_name):\n",
    "    \n",
    "    program_start = time.time()\n",
    "    \n",
    "    # Open/Create a file to append data\n",
    "    csvFile = open(csv_file_name, 'a')\n",
    "    #Use csv Writer\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "    csvWriter.writerow(['user_name', 'user_desc', 'location', 'following',\n",
    "                                        'followers', 'totaltweets', 'user_createdts', 'tweet_createdts',\n",
    "                                        'retweet_count', 'text'])\n",
    "    for i in range(0, num_runs):\n",
    "        new_tweets = tweepy.Cursor(api.search, q=search_words, lang=\"en\", tweet_mode='extended').items(num_tweets)\n",
    "        \n",
    "        # transform the tweepy tweets into a 2D array \n",
    "        outtweets = [[tweet.user.screen_name,tweet.user.description,tweet.user.location,tweet.user.friends_count,\n",
    "                  tweet.user.followers_count,tweet.user.statuses_count,tweet.user.created_at,\n",
    "                  tweet.created_at,tweet.retweet_count, tweet.full_text] for tweet in new_tweets]\n",
    "        \n",
    "        csvWriter.writerows(outtweets)\n",
    "        print(\"{} run completed!\".format(i+1))\n",
    "        time.sleep(920) #15 minute sleep time\n",
    "    \n",
    "    program_end = time.time()\n",
    "    print('Scraping has completed!')\n",
    "    print('Total time taken to scrape is {} minutes.'.format(round(program_end - program_start)/60, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 run completed!\n",
      "2 run completed!\n",
      "3 run completed!\n",
      "4 run completed!\n",
      "5 run completed!\n",
      "6 run completed!\n",
      "7 run completed!\n",
      "8 run completed!\n",
      "9 run completed!\n",
      "10 run completed!\n",
      "11 run completed!\n",
      "12 run completed!\n",
      "13 run completed!\n",
      "14 run completed!\n",
      "15 run completed!\n",
      "16 run completed!\n",
      "17 run completed!\n",
      "18 run completed!\n",
      "19 run completed!\n",
      "20 run completed!\n",
      "21 run completed!\n",
      "22 run completed!\n",
      "23 run completed!\n",
      "24 run completed!\n",
      "25 run completed!\n",
      "26 run completed!\n",
      "27 run completed!\n",
      "28 run completed!\n",
      "29 run completed!\n",
      "30 run completed!\n",
      "31 run completed!\n",
      "32 run completed!\n",
      "33 run completed!\n",
      "34 run completed!\n",
      "35 run completed!\n",
      "36 run completed!\n",
      "37 run completed!\n",
      "38 run completed!\n",
      "39 run completed!\n",
      "40 run completed!\n",
      "41 run completed!\n",
      "42 run completed!\n",
      "43 run completed!\n",
      "44 run completed!\n",
      "45 run completed!\n",
      "46 run completed!\n",
      "47 run completed!\n",
      "48 run completed!\n",
      "49 run completed!\n",
      "50 run completed!\n",
      "Scraping has completed!\n",
      "Total time taken to scrape is 770.7666666666667 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Initialise these variables for #fitness\n",
    "search_words = \"#fitness OR #workout OR #gym OR #healthy OR #fitnessmotivation OR #fitnessmodel OR #healthylifestyle OR #fit OR #mtivation OR #wellness OR #lifestyle OR #mindbody OR #training OR #exercise OR #exercise OR #firnesslife OR #healthandfitness OR #exercisemotivation\"\n",
    "num_tweets = 200\n",
    "num_runs = 50\n",
    "csv_file_name = 'fitness_tweets.csv'\n",
    "\n",
    "\n",
    "# Call the function scrape_tweets\n",
    "scrape_tweets(search_words, num_tweets, num_runs, csv_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_desc</th>\n",
       "      <th>location</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>totaltweets</th>\n",
       "      <th>user_createdts</th>\n",
       "      <th>tweet_createdts</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anusualauthor</td>\n",
       "      <td>official tweet of Enigma Anu Aggarwal</td>\n",
       "      <td>Mumbai, India</td>\n",
       "      <td>544</td>\n",
       "      <td>3743</td>\n",
       "      <td>2661</td>\n",
       "      <td>2010-04-30 12:38:54</td>\n",
       "      <td>2020-10-05 15:34:17</td>\n",
       "      <td>0</td>\n",
       "      <td>You get to know your #true #nature in that mom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WhtIStheSCIENCE</td>\n",
       "      <td>Clinical Director #BCBA for @SpecialNeedsLA #A...</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>1008</td>\n",
       "      <td>696</td>\n",
       "      <td>7214</td>\n",
       "      <td>2012-10-15 06:38:35</td>\n",
       "      <td>2020-10-05 15:34:07</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @SpectrumSports8: Cone Flip Melee!! \\n\\n#do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HeathAJordan</td>\n",
       "      <td>Entrepreneur/ Filmmaker/ CEO/ Producer/ Direct...</td>\n",
       "      <td>Sarasota Florida</td>\n",
       "      <td>6775</td>\n",
       "      <td>8567</td>\n",
       "      <td>50578</td>\n",
       "      <td>2011-06-21 22:56:28</td>\n",
       "      <td>2020-10-05 15:34:03</td>\n",
       "      <td>0</td>\n",
       "      <td>#RT @lucaslagoons: RT @LagoonsDesign: Want to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CeciliaMaundu</td>\n",
       "      <td>Broadcast journalist, Specialist in Gender Dig...</td>\n",
       "      <td>Nairobi</td>\n",
       "      <td>888</td>\n",
       "      <td>754</td>\n",
       "      <td>7282</td>\n",
       "      <td>2012-01-11 04:09:14</td>\n",
       "      <td>2020-10-05 15:34:00</td>\n",
       "      <td>4</td>\n",
       "      <td>RT @PollicyOrg: Register for our next hands-on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LidiaSegundoCar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>722</td>\n",
       "      <td>772</td>\n",
       "      <td>591</td>\n",
       "      <td>2019-04-09 00:48:01</td>\n",
       "      <td>2020-10-05 15:33:54</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @petertamayo: Nada #cambia si tu no cambias...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_name                                          user_desc  \\\n",
       "0    anusualauthor              official tweet of Enigma Anu Aggarwal   \n",
       "1  WhtIStheSCIENCE  Clinical Director #BCBA for @SpecialNeedsLA #A...   \n",
       "2     HeathAJordan  Entrepreneur/ Filmmaker/ CEO/ Producer/ Direct...   \n",
       "3    CeciliaMaundu  Broadcast journalist, Specialist in Gender Dig...   \n",
       "4  LidiaSegundoCar                                                NaN   \n",
       "\n",
       "           location  following  followers  totaltweets       user_createdts  \\\n",
       "0     Mumbai, India        544       3743         2661  2010-04-30 12:38:54   \n",
       "1   Los Angeles, CA       1008        696         7214  2012-10-15 06:38:35   \n",
       "2  Sarasota Florida       6775       8567        50578  2011-06-21 22:56:28   \n",
       "3           Nairobi        888        754         7282  2012-01-11 04:09:14   \n",
       "4               NaN        722        772          591  2019-04-09 00:48:01   \n",
       "\n",
       "       tweet_createdts  retweet_count  \\\n",
       "0  2020-10-05 15:34:17              0   \n",
       "1  2020-10-05 15:34:07              1   \n",
       "2  2020-10-05 15:34:03              0   \n",
       "3  2020-10-05 15:34:00              4   \n",
       "4  2020-10-05 15:33:54              1   \n",
       "\n",
       "                                                text  \n",
       "0  You get to know your #true #nature in that mom...  \n",
       "1  RT @SpectrumSports8: Cone Flip Melee!! \\n\\n#do...  \n",
       "2  #RT @lucaslagoons: RT @LagoonsDesign: Want to ...  \n",
       "3  RT @PollicyOrg: Register for our next hands-on...  \n",
       "4  RT @petertamayo: Nada #cambia si tu no cambias...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data into a pandas DataFrame\n",
    "fitness_df = pd.read_csv('fitness_tweets.csv')\n",
    "fitness_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   user_name        10000 non-null  object\n",
      " 1   user_desc        9113 non-null   object\n",
      " 2   location         7244 non-null   object\n",
      " 3   following        10000 non-null  int64 \n",
      " 4   followers        10000 non-null  int64 \n",
      " 5   totaltweets      10000 non-null  int64 \n",
      " 6   user_createdts   10000 non-null  object\n",
      " 7   tweet_createdts  10000 non-null  object\n",
      " 8   retweet_count    10000 non-null  int64 \n",
      " 9   text             10000 non-null  object\n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "fitness_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3895"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicate tweets \n",
    "\n",
    "duplicate_tweets_fitness = fitness_df.duplicated(subset='text', keep='first').sum()\n",
    "duplicate_tweets_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7436"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of users having less than 2000 followers\n",
    "fitness_less2k = fitness_df[fitness_df['followers'] < 2000]\n",
    "len(fitness_less2k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2563"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of users having more than 2000 followers\n",
    "fitness_more2k = fitness_df[fitness_df['followers'] > 2000]\n",
    "len(fitness_more2k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling tweets for #travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 run completed!\n",
      "2 run completed!\n",
      "3 run completed!\n",
      "4 run completed!\n",
      "5 run completed!\n",
      "6 run completed!\n",
      "7 run completed!\n",
      "8 run completed!\n",
      "9 run completed!\n",
      "10 run completed!\n",
      "11 run completed!\n",
      "12 run completed!\n",
      "13 run completed!\n",
      "14 run completed!\n",
      "15 run completed!\n",
      "16 run completed!\n",
      "17 run completed!\n",
      "18 run completed!\n",
      "19 run completed!\n",
      "20 run completed!\n",
      "21 run completed!\n",
      "22 run completed!\n",
      "23 run completed!\n",
      "24 run completed!\n",
      "25 run completed!\n",
      "26 run completed!\n",
      "27 run completed!\n",
      "28 run completed!\n",
      "29 run completed!\n",
      "30 run completed!\n",
      "31 run completed!\n",
      "32 run completed!\n",
      "33 run completed!\n",
      "34 run completed!\n",
      "35 run completed!\n",
      "36 run completed!\n",
      "37 run completed!\n",
      "38 run completed!\n",
      "39 run completed!\n",
      "40 run completed!\n",
      "41 run completed!\n",
      "42 run completed!\n",
      "43 run completed!\n",
      "44 run completed!\n",
      "45 run completed!\n",
      "46 run completed!\n",
      "47 run completed!\n",
      "48 run completed!\n",
      "49 run completed!\n",
      "50 run completed!\n",
      "Scraping has completed!\n",
      "Total time taken to scrape is 771.0666666666667 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Initialise these variables for #travel\n",
    "search_words = \"#travel OR #traveltips OR #trip OR #travelskills OR #travelblog OR #travelling OR #travellingtheworld OR #vacation OR #travelphotography OR #holidays OR #tour OR #traveler OR #travelgram OR #travelbloggers OR #travelblogging OR #tourism OR #budgettravel\"\n",
    "num_tweets = 200\n",
    "num_runs = 50\n",
    "csv_file_name = 'travel_tweets.csv'\n",
    "\n",
    "\n",
    "# Call the function scrape_tweets\n",
    "scrape_tweets(search_words, num_tweets, num_runs, csv_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_desc</th>\n",
       "      <th>location</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>totaltweets</th>\n",
       "      <th>user_createdts</th>\n",
       "      <th>tweet_createdts</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kthjkuwu</td>\n",
       "      <td>Ë—ËË‹ I love you MORE than yesterday and LESS th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1160</td>\n",
       "      <td>302</td>\n",
       "      <td>21909</td>\n",
       "      <td>2015-05-23 17:04:00</td>\n",
       "      <td>2020-10-06 15:21:27</td>\n",
       "      <td>9223</td>\n",
       "      <td>RT @RBW_MAMAMOO: [#ë§ˆë§ˆë¬´]\\n\\nMAMAMOO 10th\\nMini ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nayeon1727228</td>\n",
       "      <td>TwiceğŸ’–ğŸ’–</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130</td>\n",
       "      <td>5</td>\n",
       "      <td>1709</td>\n",
       "      <td>2020-06-21 16:28:11</td>\n",
       "      <td>2020-10-06 15:21:27</td>\n",
       "      <td>9223</td>\n",
       "      <td>RT @RBW_MAMAMOO: [#ë§ˆë§ˆë¬´]\\n\\nMAMAMOO 10th\\nMini ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seoulbyjoon_</td>\n",
       "      <td>ğ‘ºğ’•ğ’“ğ’†ğ’‚ğ’ ğ‘«ğ’€ğ‘µğ’‚ğ’ğ’Šğ‘»ğ‘¬ğŸ’¿ğŸ“¼  ğ‘ºğ’•ğ’“ğ’†ğ’‚ğ’ ğ‘¾ğ’‚ğ’ğ’ğ’‚ ğ‘©ğ’† ğ‘´ğ’šğ’”ğ’†ğ’ğ’‡ ğŸ’—ğŸ’šğŸ’™ğŸ’œ...</td>\n",
       "      <td>s/hâ€¢15â€¢ğŸ‡²ğŸ‡½â€¢CA</td>\n",
       "      <td>474</td>\n",
       "      <td>276</td>\n",
       "      <td>9005</td>\n",
       "      <td>2018-12-04 01:11:37</td>\n",
       "      <td>2020-10-06 15:21:27</td>\n",
       "      <td>9223</td>\n",
       "      <td>RT @RBW_MAMAMOO: [#ë§ˆë§ˆë¬´]\\n\\nMAMAMOO 10th\\nMini ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wheemoonve</td>\n",
       "      <td>moomoo-tomoon-weve fan account | she/her.</td>\n",
       "      <td>01l | broken eng/ina</td>\n",
       "      <td>477</td>\n",
       "      <td>429</td>\n",
       "      <td>16205</td>\n",
       "      <td>2020-07-31 11:58:21</td>\n",
       "      <td>2020-10-06 15:21:26</td>\n",
       "      <td>0</td>\n",
       "      <td>chop chop mumu time to diligently collect star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>namchildz</td>\n",
       "      <td>â € â €â €       ğƒ-ğŸâ €â€â€”â €ğ˜ğ—¿ğ—®ğ—°ğ—¸ ğŸ¯â €:â €ğ—´ğ—¼ ğ—³ğ˜‚ğ—°ğ—¸ ğ˜†ğ—¼ğ˜‚ğ—¿ğ˜€ğ—²ğ—¹ğ—³  ...</td>\n",
       "      <td>only army</td>\n",
       "      <td>1933</td>\n",
       "      <td>2855</td>\n",
       "      <td>176342</td>\n",
       "      <td>2014-03-07 17:11:01</td>\n",
       "      <td>2020-10-06 15:21:26</td>\n",
       "      <td>9223</td>\n",
       "      <td>RT @RBW_MAMAMOO: [#ë§ˆë§ˆë¬´]\\n\\nMAMAMOO 10th\\nMini ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_name                                          user_desc  \\\n",
       "0       kthjkuwu  Ë—ËË‹ I love you MORE than yesterday and LESS th...   \n",
       "1  nayeon1727228                                            TwiceğŸ’–ğŸ’–   \n",
       "2   seoulbyjoon_  ğ‘ºğ’•ğ’“ğ’†ğ’‚ğ’ ğ‘«ğ’€ğ‘µğ’‚ğ’ğ’Šğ‘»ğ‘¬ğŸ’¿ğŸ“¼  ğ‘ºğ’•ğ’“ğ’†ğ’‚ğ’ ğ‘¾ğ’‚ğ’ğ’ğ’‚ ğ‘©ğ’† ğ‘´ğ’šğ’”ğ’†ğ’ğ’‡ ğŸ’—ğŸ’šğŸ’™ğŸ’œ...   \n",
       "3     wheemoonve          moomoo-tomoon-weve fan account | she/her.   \n",
       "4      namchildz  â € â €â €       ğƒ-ğŸâ €â€â€”â €ğ˜ğ—¿ğ—®ğ—°ğ—¸ ğŸ¯â €:â €ğ—´ğ—¼ ğ—³ğ˜‚ğ—°ğ—¸ ğ˜†ğ—¼ğ˜‚ğ—¿ğ˜€ğ—²ğ—¹ğ—³  ...   \n",
       "\n",
       "               location  following  followers  totaltweets  \\\n",
       "0                   NaN       1160        302        21909   \n",
       "1                   NaN        130          5         1709   \n",
       "2         s/hâ€¢15â€¢ğŸ‡²ğŸ‡½â€¢CA         474        276         9005   \n",
       "3  01l | broken eng/ina        477        429        16205   \n",
       "4             only army       1933       2855       176342   \n",
       "\n",
       "        user_createdts      tweet_createdts  retweet_count  \\\n",
       "0  2015-05-23 17:04:00  2020-10-06 15:21:27           9223   \n",
       "1  2020-06-21 16:28:11  2020-10-06 15:21:27           9223   \n",
       "2  2018-12-04 01:11:37  2020-10-06 15:21:27           9223   \n",
       "3  2020-07-31 11:58:21  2020-10-06 15:21:26              0   \n",
       "4  2014-03-07 17:11:01  2020-10-06 15:21:26           9223   \n",
       "\n",
       "                                                text  \n",
       "0  RT @RBW_MAMAMOO: [#ë§ˆë§ˆë¬´]\\n\\nMAMAMOO 10th\\nMini ...  \n",
       "1  RT @RBW_MAMAMOO: [#ë§ˆë§ˆë¬´]\\n\\nMAMAMOO 10th\\nMini ...  \n",
       "2  RT @RBW_MAMAMOO: [#ë§ˆë§ˆë¬´]\\n\\nMAMAMOO 10th\\nMini ...  \n",
       "3  chop chop mumu time to diligently collect star...  \n",
       "4  RT @RBW_MAMAMOO: [#ë§ˆë§ˆë¬´]\\n\\nMAMAMOO 10th\\nMini ...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data into a pandas DataFrame\n",
    "travel_df = pd.read_csv('travel_tweets.csv')\n",
    "travel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "travel_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   user_name        10000 non-null  object\n",
      " 1   user_desc        8968 non-null   object\n",
      " 2   location         6326 non-null   object\n",
      " 3   following        10000 non-null  int64 \n",
      " 4   followers        10000 non-null  int64 \n",
      " 5   totaltweets      10000 non-null  int64 \n",
      " 6   user_createdts   10000 non-null  object\n",
      " 7   tweet_createdts  10000 non-null  object\n",
      " 8   retweet_count    10000 non-null  int64 \n",
      " 9   text             10000 non-null  object\n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "travel_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6384"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicate tweets \n",
    "\n",
    "duplicate_tweets_travel = travel_df.duplicated(subset='text', keep='first').sum()\n",
    "duplicate_tweets_travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet Preprocessing\n",
    "\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation \n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "class PreProcessTweets:\n",
    "    def __init__(self):\n",
    "        self._stopwords = set(stopwords.words('english') + list(punctuation) + ['AT_USER','URL'])\n",
    "        \n",
    "    def processTweets(self, list_of_tweets):\n",
    "        processedTweets=[]\n",
    "        for tweet in list_of_tweets:\n",
    "            processedTweets.append((self._processTweet(tweet[\"text\"]),tweet[\"label\"]))\n",
    "        return processedTweets\n",
    "    \n",
    "    def _processTweet(self, tweet):\n",
    "        tweet = tweet.lower() # convert text to lower-case\n",
    "        tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', tweet) # remove URLs\n",
    "        tweet = re.sub('@[^\\s]+', 'AT_USER', tweet) # remove usernames\n",
    "        tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet) # remove the # in #hashtag\n",
    "        tweet = word_tokenize(tweet) # remove repeated characters (helloooooooo into hello)\n",
    "        return [word for word in tweet if word not in self._stopwords]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
